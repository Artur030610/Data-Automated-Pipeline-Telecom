import duckdb
import pandas as pd
import os
import sys
import glob
import re
from datetime import datetime

# --- EL TRUCO DEL ASCENSOR ---
current_dir = os.path.dirname(os.path.abspath(__file__))
parent_dir = os.path.dirname(current_dir)
sys.path.append(parent_dir)

from config import PATHS
from utils import reportar_tiempo, console

# Mapa para convertir meses texto a nÃºmero dentro de DuckDB
MAPA_MESES_SQL = """
    CASE UPPER(TRIM(MES_NOMBRE))
        WHEN 'ENERO' THEN 1 WHEN 'FEBRERO' THEN 2 WHEN 'MARZO' THEN 3 
        WHEN 'ABRIL' THEN 4 WHEN 'MAYO' THEN 5 WHEN 'JUNIO' THEN 6 
        WHEN 'JULIO' THEN 7 WHEN 'AGOSTO' THEN 8 WHEN 'SEPTIEMBRE' THEN 9 
        WHEN 'OCTUBRE' THEN 10 WHEN 'NOVIEMBRE' THEN 11 WHEN 'DICIEMBRE' THEN 12
        ELSE NULL 
    END
"""

def obtener_archivos_clave(ruta_directorio):
    """
    Analiza los nombres de archivo Data_AbonadosDDMMYYYY.xlsx
    Retorna: { 2024: {'fecha': datetime, 'ruta': path}, ... }
    Solo se queda con la versiÃ³n mÃ¡s reciente encontrada para cada aÃ±o.
    """
    archivos = glob.glob(os.path.join(ruta_directorio, "Data_Abonados*.xlsx"))
    mejores_archivos = {}
    
    patron = r"Data_Abonados(\d{2})(\d{2})(\d{4})" # Captura DD, MM, YYYY

    for archivo in archivos:
        nombre = os.path.basename(archivo)
        match = re.search(patron, nombre)
        
        if match:
            dia, mes, anio = match.groups()
            try:
                # Convertimos a int para comparar
                fecha_archivo = datetime(int(anio), int(mes), int(dia))
                anio_num = int(anio)
                
                # Si es el primer archivo de ese aÃ±o O es mÃ¡s reciente que el que tenÃ­amos
                if anio_num not in mejores_archivos or fecha_archivo > mejores_archivos[anio_num]['fecha']:
                    mejores_archivos[anio_num] = {
                        'fecha': fecha_archivo,
                        'ruta': archivo
                    }
            except ValueError:
                continue

    return mejores_archivos

@reportar_tiempo
def ejecutar():
    console.rule("[bold cyan]14. ETL: ESTADÃSTICA ABONADOS (HISTÃ“RICO ANUAL)[/]")

    # 1. DEFINICIÃ“N DE RUTAS
    RUTA_RAW = PATHS["raw_estad_abonados"]
    NOMBRE_GOLD = "Estadistica_Abonados_Historico.parquet"
    RUTA_GOLD_COMPLETA = os.path.join(PATHS.get("gold", "data/gold"), NOMBRE_GOLD)
    
    # 2. SELECCIÃ“N INTELIGENTE DE ARCHIVOS
    archivos_clave = obtener_archivos_clave(RUTA_RAW)
    
    if not archivos_clave:
        console.print(f"[error]âŒ No se encontraron archivos vÃ¡lidos (Data_Abonados*.xlsx) en: {RUTA_RAW}[/]")
        return

    console.print(f"[info]ðŸ“… Archivos seleccionados para la historia:[/]")
    for anio, data in sorted(archivos_clave.items()):
        console.print(f"  â€¢ AÃ±o [bold yellow]{anio}[/]: {os.path.basename(data['ruta'])} ({data['fecha'].strftime('%d/%m/%Y')})")

    # 3. PROCESAMIENTO CON DUCKDB
    con = duckdb.connect(database=':memory:')
    
    # Lista para acumular las sub-queries de cada aÃ±o
    queries_union = []

    try:
        console.print("[cyan]âš™ï¸  Procesando e ingiriendo archivos Excel...[/]")
        
        for anio, data in archivos_clave.items():
            archivo = data['ruta']
            nombre_tabla = f"raw_{anio}"
            
            # A. Leemos Excel con Pandas (usando engine='calamine' si estÃ¡ disponible, es mÃ¡s rÃ¡pido)
            try:
                df_temp = pd.read_excel(archivo, engine="calamine")
            except ImportError:
                # Fallback a openpyxl si calamine no estÃ¡ instalado
                df_temp = pd.read_excel(archivo, engine="openpyxl")
            
            # B. Limpieza bÃ¡sica de columnas para SQL
            df_temp.columns = df_temp.columns.astype(str).str.strip().str.upper()
            
            # C. Registramos el DataFrame como tabla virtual en DuckDB
            con.register(nombre_tabla, df_temp)
            
            # D. Construimos la Query del AÃ±o (Unpivot + InyecciÃ³n de AÃ±o + Fecha Real)
            query_anio = f"""
                SELECT 
                    ESTATUS,
                    UPPER(TRIM(Mes)) AS MES_NOMBRE,
                    {anio} AS ANIO,
                    make_date({anio}, {MAPA_MESES_SQL}, 1) AS FECHA_CORTE,
                    TRY_CAST(Cantidad AS INTEGER) AS CANTIDAD
                FROM {nombre_tabla}
                UNPIVOT (
                    Cantidad FOR Mes IN (COLUMNS(* EXCLUDE (ESTATUS)))
                )
                WHERE ESTATUS IN ('ACTIVO', 'ANULADO', 'CORTADO')
                  AND Cantidad IS NOT NULL
                  AND TRY_CAST(Cantidad AS INTEGER) > 0
            """
            queries_union.append(query_anio)

        # 4. UNIÃ“N Y EXPORTACIÃ“N MASIVA
        if queries_union:
            # Unimos todas las partes con UNION ALL
            query_maestra = " UNION ALL ".join(queries_union)

            console.print("[info]ðŸ¦† Ejecutando transformaciÃ³n y guardado en Parquet...[/]")
            
            # Ejecutamos el COPY directo a Parquet (SÃºper eficiente)
            con.execute(f"""
                COPY ({query_maestra}) 
                TO '{RUTA_GOLD_COMPLETA}' 
                (FORMAT PARQUET, COMPRESSION 'SNAPPY')
            """)
            
            # 5. VALIDACIÃ“N FINAL
            resumen = con.execute(f"""
                SELECT ANIO, COUNT(*) as Filas, SUM(CANTIDAD) as Total_Clientes
                FROM '{RUTA_GOLD_COMPLETA}' 
                GROUP BY ANIO 
                ORDER BY ANIO
            """).fetchall()
            
            console.print("\n[bold white]ðŸ“Š Resumen por AÃ±o Procesado:[/]")
            for row in resumen:
                console.print(f"  â€¢ {row[0]}: {row[1]:,} filas | {row[2]:,} abonados (suma)")
            
            console.print(f"\n[bold green]âœ… Archivo Gold generado exitosamente: {NOMBRE_GOLD}[/]")

    except Exception as e:
        console.print(f"[bold red]ðŸ’¥ Error crÃ­tico procesando la data: {e}[/]")
    
    finally:
        con.close()

if __name__ == "__main__":
    ejecutar()