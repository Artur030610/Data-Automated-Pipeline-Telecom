import pandas as pd
import numpy as np
import os
from config import PATHS, FOLDERS_ACT_DATOS
from utils import leer_carpeta, guardar_parquet, reportar_tiempo, console

@reportar_tiempo
def ejecutar():
    console.rule("[bold magenta]5. ETL: ACTUALIZACI√ìN DE DATOS (ESTRATEGIA POWER QUERY)[/]")
    
    # --- 1. DEFINICI√ìN DE ESTRUCTURAS ---
    # Columnas que TODOS tienen en com√∫n
    cols_comunes = [
        "N¬∞ Abonado", "Estatus", "Saldo", 
        "Tipo Respuesta", "Responsable", "Suscripci√≥n", 
        "Grupo Afinidad", "Ciudad", "Zona", "Barrio", "Direcci√≥n"
    ]

    # Lista para guardar los DataFrames limpios
    dfs_para_anexar = []
    
    base_path = PATHS["raw_act_datos"] 

    # --- 2. PROCESAMIENTO POR FUENTE (CARPETA POR CARPETA) ---
    
    for carpeta in FOLDERS_ACT_DATOS:
        ruta_completa = os.path.join(base_path, carpeta)
        console.print(f"[cyan]üìÇ Procesando fuente: {carpeta}...[/]")
        
        # --- ESTRATEGIA A: CALL CENTER y OOCC ---
        # Regla: Tienen "Fecha Llamada" y "Hora Llamada". "Franquicia" suele llamarse as√≠.
        if "CALL CENTER" in carpeta or "OOCC" in carpeta:
            # Definimos inputs espec√≠ficos para esta fuente
            cols_source = cols_comunes + ["Fecha Llamada", "Hora Llamada", "Detalle Respuesta", "Franquicia"]
            
            df_temp = leer_carpeta(ruta_completa, columnas_esperadas=cols_source, filtro_exclusion="Consolidado")
            
            if not df_temp.empty:
                # Transformaci√≥n INMEDIATA (Homologaci√≥n)
                df_temp = df_temp.rename(columns={
                    "Fecha Llamada": "Fecha",
                    "Hora Llamada": "Hora",
                    "Franquicia": "Nombre Franquicia"
                })
                dfs_para_anexar.append(df_temp)

        # --- ESTRATEGIA B: OBSERVACIONES ---
        # Regla: Tienen "Fecha", "Hora", y el detalle est√° en "Observacion" o "Asunto".
        elif "OBSERVACIONES" in carpeta:
            # Probamos traer variantes de detalle
            cols_source = cols_comunes + ["Fecha", "Hora", "Observacion", "Asunto", "Franquicia"]
            
            df_temp = leer_carpeta(ruta_completa, columnas_esperadas=cols_source, filtro_exclusion="Consolidado")
            
            if not df_temp.empty:
                # 1. Unificamos el detalle (Observacion o Asunto -> Detalle Respuesta)
                if "Detalle Respuesta" not in df_temp.columns:
                    df_temp["Detalle Respuesta"] = np.nan
                
                # Prioridad: Observacion > Asunto
                if "Observacion" in df_temp.columns:
                    df_temp["Detalle Respuesta"] = df_temp["Detalle Respuesta"].fillna(df_temp["Observacion"])
                if "Asunto" in df_temp.columns:
                    df_temp["Detalle Respuesta"] = df_temp["Detalle Respuesta"].fillna(df_temp["Asunto"])
                
                # 2. Homologaci√≥n final
                df_temp = df_temp.rename(columns={"Franquicia": "Nombre Franquicia"})
                
                # Limpieza de columnas auxiliares que ya usamos
                cols_drop = ["Observacion", "Asunto"]
                df_temp = df_temp.drop(columns=[c for c in cols_drop if c in df_temp.columns])
                
                dfs_para_anexar.append(df_temp)

    # --- 3. CONSOLIDACI√ìN (ANEXAR) ---
    if not dfs_para_anexar: 
        console.print("[warning]‚ö†Ô∏è No se encontraron datos en ninguna carpeta.[/]")
        return

    # Como ya todos se llaman "Fecha" y "Detalle Respuesta", el concat es perfecto
    df = pd.concat(dfs_para_anexar, ignore_index=True)
    filas_raw = len(df)
    console.print(f"[green]‚úÖ Uni√≥n exitosa. Total registros brutos: {filas_raw}[/]")

    # --- 4. TRANSFORMACI√ìN FINAL (LIMPIEZA COM√öN) ---
    
    # Fechas (Ya todo est√° en la columna "Fecha")
    df["Fecha"] = pd.to_datetime(df["Fecha"], dayfirst=True, errors="coerce")
    
    # Origen
    df["Origen"] = df["Source.Name"].astype(str).str.upper()

    # Limpieza Texto Detalle
    df["Detalle Respuesta"] = df["Detalle Respuesta"].fillna("").astype(str).str.upper().str.strip()
    df["Detalle Respuesta"] = df["Detalle Respuesta"].str.split("ANT: ").str[0].str.strip()

    # Reemplazos est√°ndar
    reemplazos = {
        "EMAIL": "CORREO ELECTR√ìNICO",
        "C√âDULA DE IDENTIDAD": "CEDULA",
        "CELULAR": "TELEFONO",
        "N√öMERO TELEF√ìNICO": "TELEFONO"
    }
    for viejo, nuevo in reemplazos.items():
        df["Detalle Respuesta"] = df["Detalle Respuesta"].str.replace(viejo, nuevo, regex=False)

    # --- 5. AUDITOR√çA Y FILTRADO DE NULOS ---
    
    # Columnas finales deseadas
    cols_finales = [
        "Origen", "N¬∞ Abonado", "Estatus", "Fecha", "Hora", 
        "Detalle Respuesta", "Responsable", "Suscripci√≥n", 
        "Grupo Afinidad", "Nombre Franquicia", "Ciudad"
    ]
    
    # Reindex para ordenar y asegurar estructura
    df_final = df.reindex(columns=cols_finales)
    
    # Auditor√≠a de Fechas Nulas
    nulos_fecha = df_final["Fecha"].isna().sum()
    if nulos_fecha > 0:
        # Opcional: Eliminar los nulos si confirmamos que no sirven
        # df_final = df_final.dropna(subset=['Fecha'])
        console.print(f"[yellow]‚ö†Ô∏è Advertencia: Quedaron {nulos_fecha} registros sin fecha v√°lida (eran nulos en origen o formato incorrecto).[/]")
    
    df_final = df_final.drop_duplicates()

    # --- 6. CARGA ---
    guardar_parquet(
        df_final, 
        "Actualizacion_Datos_Gold.parquet",
        filas_iniciales=filas_raw
    )